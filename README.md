# PAN & Aadhaar Document Extraction System

A sophisticated, production-ready document processing solution designed to extract, validate, and manage information from Indian government identity documents. The system leverages advanced OCR technology, AI-powered validation, and a multi-agent workflow architecture to provide high-accuracy document processing capabilities.

## ğŸš€ Key Features

- **Multi-Agent Architecture**: Six specialized agents working in coordination
- **90% Reduction in Manual Data Entry**: Automated processing eliminates manual document handling
- **95%+ Accuracy**: High precision in document classification and field extraction
- **LangGraph Workflow**: Sophisticated workflow orchestration with state management
- **Dynamic Database**: Automatic table creation and schema management
- **Advanced OCR**: Tesseract with image preprocessing and enhancement
- **Comprehensive Validation**: Multi-layer validation with confidence scoring
- **Batch Processing**: Process thousands of documents efficiently
- **Local Processing**: Minimal external dependencies for core functionality

## ğŸ“‹ Supported Documents

### Aadhaar Cards
- **Extracted Fields**: Aadhaar Number, Name, Date of Birth, Gender, Address, Father's/Guardian's Name
- **Validation**: 12-digit number format, masked/unmasked patterns
- **Accuracy**: 95%+ for good quality documents

### PAN Cards
- **Extracted Fields**: PAN Number, Name, Father's Name, Date of Birth
- **Validation**: 10-character alphanumeric format (5 letters + 4 digits + 1 letter)
- **Accuracy**: 95%+ for good quality documents

## ğŸ—ï¸ System Architecture

```
Document Input â†’ LangGraph Workflow â†’ Multi-Agent System â†’ Database Storage
     â”‚                    â”‚                    â”‚                    â”‚
     â–¼                    â–¼                    â–¼                    â–¼
PDF/Image         Workflow Engine      Specialized Agents    SQLite Database
Processing        State Management     Field Extraction      User Management
OCR Processing    Conditional Routing  Validation           Processing Logs
```

### Multi-Agent System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Agent System                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Extractor   â”‚  â”‚ Classifier  â”‚  â”‚ Validator   â”‚        â”‚
â”‚  â”‚   Agent     â”‚  â”‚   Agent     â”‚  â”‚   Agent     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚               â”‚               â”‚                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Database    â”‚  â”‚ Orchestratorâ”‚  â”‚ Reader      â”‚        â”‚
â”‚  â”‚   Agent     â”‚  â”‚   Agent     â”‚  â”‚   Agent     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Processing Workflow

```
Document Input
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Extraction    â”‚ â”€â”€â–¶ OCR Processing
â”‚     Node        â”‚ â”€â”€â–¶ Text Cleaning
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”€â”€â–¶ Field Detection
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Classification  â”‚ â”€â”€â–¶ Pattern Matching
â”‚     Node        â”‚ â”€â”€â–¶ Document Type Detection
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”€â”€â–¶ Routing Decision
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Specialized    â”‚ â”€â”€â–¶ Aadhaar Extractor
â”‚   Extractors    â”‚ â”€â”€â–¶ PAN Extractor
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”€â”€â–¶ Manual Review (if needed)
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Validation     â”‚ â”€â”€â–¶ Field Validation
â”‚     Node        â”‚ â”€â”€â–¶ Pattern Verification
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”€â”€â–¶ Confidence Scoring
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Analysis      â”‚ â”€â”€â–¶ Quality Assessment
â”‚     Node        â”‚ â”€â”€â–¶ Insights Generation
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”€â”€â–¶ Recommendations
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Finalization   â”‚ â”€â”€â–¶ Result Compilation
â”‚     Node        â”‚ â”€â”€â–¶ Database Storage
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”€â”€â–¶ Status Reporting
     â”‚
     â–¼
   Output
```

## ğŸ› ï¸ Installation & Setup

### Prerequisites

- **Python**: 3.8 or higher
- **Node.js**: 14.0 or higher (for frontend)
- **npm**: 6.0 or higher
- **Tesseract OCR**: Latest version

### 1. Clone Repository

```bash
git clone <repository-url>
cd pan-aadhaar-extraction-system
```

### 2. Install Tesseract OCR

**Windows**:
```bash
# Download from GitHub releases
# https://github.com/UB-Mannheim/tesseract/wiki
# Add to PATH environment variable
```

**macOS**:
```bash
brew install tesseract
```

**Linux (Ubuntu/Debian)**:
```bash
sudo apt-get update
sudo apt-get install tesseract-ocr
```

### 3. Backend Setup

```bash
# Navigate to backend folder
cd backend

# Create virtual environment
python -m venv env

# Activate virtual environment
# Windows:
env\Scripts\activate
# macOS/Linux:
source env/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure environment variables
cp .env.example .env
# Edit .env with your configuration

# Run the backend application
python simple_app.py
```

### 4. Frontend Setup

```bash
# Navigate to frontend folder
cd frontend

# Install dependencies
npm install

# Start the frontend application
npm start
```

## âš™ï¸ Configuration

Create a `.env` file in the backend folder with the following settings:

```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4

# OCR Configuration
TESSERACT_CMD=tesseract
PDF_DPI=400
MAX_PAGES_TO_PROCESS=2
OCR_LANGUAGES=eng
OCR_PSM_MODES=6,8,13

# Processing Settings
LANGGRAPH_VERBOSE=True
MIN_CONFIDENCE_SCORE=0.7
ENABLE_IMAGE_PREPROCESSING=True
ENABLE_ORIENTATION_CORRECTION=True
MAX_FILE_SIZE_MB=50

# Output Settings
OUTPUT_DIR=output
LOGS_DIR=logs

# Database Configuration
DATABASE_PATH=data/
```

## ğŸš€ Usage

### Web Interface (Recommended)

1. Start the backend server:
   ```bash
   cd backend
   python simple_app.py
   ```

2. Start the frontend application:
   ```bash
   cd frontend
   npm start
   ```

3. Open your browser and navigate to `http://localhost:3000`

### Command Line Interface

#### Single Document Processing
```bash
cd backend
python main.py document.pdf
```

#### Batch Processing
```bash
cd backend
python main.py --batch documents/
```

#### Standalone Batch Processing
```bash
cd backend
python batch_process.py documents/ --output results.json
```

### Programmatic Integration

```python
from main import DocumentProcessor

# Initialize processor
processor = DocumentProcessor()

# Process single document
result = processor.process_document("document.pdf")
print(result)

# LangGraph workflow integration
from graph.workflow import process_document_with_graph
result = process_document_with_graph("document.pdf")
```

## ğŸ“Š Output Format

### Success Response
```json
{
  "processing_timestamp": "2024-01-01T12:00:00",
  "file_path": "document.pdf",
  "document_type": "AADHAAR",
  "validation_status": "passed",
  "extraction_confidence": 0.85,
  "overall_score": 0.92,
  "errors": [],
  "warnings": ["Address seems too short"],
  "extracted_data": {
    "Aadhaar Number": "123456789012",
    "Name": "John Doe",
    "DOB": "01/01/1990",
    "Gender": "Male",
    "Address": "123 Main Street, City, State"
  },
  "validation_details": {
    "Aadhaar Number": {"valid": true, "type": "unmasked"},
    "Name": {"valid": true, "length": 8},
    "DOB": {"valid": true, "parsed_date": "1990-01-01"}
  },
  "processing_log": [
    "[2024-01-01 12:00:00] Starting document extraction",
    "[2024-01-01 12:00:01] Extraction completed with status: success"
  ]
}
```

## ğŸ“ Project Structure

```
pan-aadhaar-extraction-system/
â”œâ”€â”€ backend/                    # Backend application
â”‚   â”œâ”€â”€ agents/                 # Agent implementations
â”‚   â”‚   â”œâ”€â”€ document_classifier_agent.py
â”‚   â”‚   â”œâ”€â”€ extractor_agent.py
â”‚   â”‚   â”œâ”€â”€ validator_agent.py
â”‚   â”‚   â”œâ”€â”€ database_agent.py
â”‚   â”‚   â”œâ”€â”€ orchestrator_agent.py
â”‚   â”‚   â””â”€â”€ reader_agent.py
â”‚   â”œâ”€â”€ graph/                  # LangGraph workflow
â”‚   â”‚   â”œâ”€â”€ state.py           # State management
â”‚   â”‚   â”œâ”€â”€ nodes.py           # Workflow nodes
â”‚   â”‚   â””â”€â”€ workflow.py        # Main workflow
â”‚   â”œâ”€â”€ tools/                  # Processing tools
â”‚   â”‚   â””â”€â”€ pdf_extractor_tool.py
â”‚   â”œâ”€â”€ utils/                  # Utilities
â”‚   â”‚   â”œâ”€â”€ file_utils.py
â”‚   â”‚   â””â”€â”€ logging_config.py
â”‚   â”œâ”€â”€ data/                   # Database storage
â”‚   â”œâ”€â”€ output/                 # Processing outputs
â”‚   â”œâ”€â”€ logs/                   # Application logs
â”‚   â”œâ”€â”€ config.py              # Configuration
â”‚   â”œâ”€â”€ main.py                # Main CLI application
â”‚   â”œâ”€â”€ simple_app.py          # Backend server
â”‚   â”œâ”€â”€ batch_process.py       # Batch processing
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â””â”€â”€ .env.example          # Environment template
â”œâ”€â”€ frontend/                   # Frontend application
â”‚   â”œâ”€â”€ src/                   # Source files
â”‚   â”œâ”€â”€ public/                # Public assets
â”‚   â”œâ”€â”€ package.json          # Node dependencies
â”‚   â””â”€â”€ README.md             # Frontend documentation
â”œâ”€â”€ docs/                      # Documentation
â”œâ”€â”€ tests/                     # Test files
â””â”€â”€ README.md                 # This file
```

## ğŸ“ˆ Performance Metrics

### Processing Times
- **Single Document**: 10-30 seconds (depending on quality)
- **Batch Processing**: Linear scaling with document count
- **OCR Processing**: 5-15 seconds per page
- **Validation**: 1-3 seconds per document

### Resource Usage
- **Memory**: 100-200MB per document
- **CPU**: Moderate usage during OCR
- **Storage**: Minimal (SQLite database)
- **Network**: Only for OpenAI API calls

### Accuracy Metrics
- **Document Classification**: 95%+ accuracy
- **Field Extraction**: 85-95% for good quality documents
- **Validation**: 90%+ accuracy for valid documents
- **OCR Quality**: 80-95% depending on image quality

## ğŸ”§ Advanced Configuration

### OCR Optimization
```python
# Image preprocessing settings
ENABLE_IMAGE_PREPROCESSING=True
ENABLE_ORIENTATION_CORRECTION=True
NOISE_REDUCTION_KERNEL_SIZE=3
ADAPTIVE_THRESHOLD_BLOCK_SIZE=11

# OCR parameters
OCR_PSM_MODES=6,8,13  # Page segmentation modes
OCR_OEM_MODE=3        # OCR Engine Mode
OCR_LANGUAGES=eng     # Language codes
```

### Database Settings
```python
# Database configuration
DATABASE_PATH=data/
MAX_CONNECTIONS=10
CONNECTION_TIMEOUT=30
ENABLE_WAL_MODE=True
```

## ğŸ§ª Testing

### Run Test Suite
```bash
cd backend
python -m pytest tests/ -v
```

### Test Coverage
```bash
cd backend
python -m pytest --cov=agents --cov=graph --cov=tools tests/
```

### Performance Testing
```bash
cd backend
python test_performance.py
```

## ğŸš€ Deployment

### Docker Deployment

#### Backend
```dockerfile
FROM python:3.9-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    tesseract-ocr \
    && rm -rf /var/lib/apt/lists/*

# Copy application
COPY backend/ /app
WORKDIR /app

# Install Python dependencies
RUN pip install -r requirements.txt

# Run application
CMD ["python", "simple_app.py"]
```

#### Frontend
```dockerfile
FROM node:16-alpine

# Copy application
COPY frontend/ /app
WORKDIR /app

# Install dependencies
RUN npm install

# Build application
RUN npm run build

# Serve static files
FROM nginx:alpine
COPY --from=0 /app/build /usr/share/nginx/html
```

### Production Deployment

#### Using Docker Compose
```yaml
version: '3.8'
services:
  backend:
    build: ./backend
    ports:
      - "5000:5000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs

  frontend:
    build: ./frontend
    ports:
      - "3000:80"
    depends_on:
      - backend
```

## ğŸ”’ Security & Compliance

### Security Features
- **Local Processing**: Minimal external data transmission
- **Encrypted Storage**: Secure API key management
- **Access Controls**: File system and database protection
- **Audit Trail**: Comprehensive logging and monitoring

### Compliance
- **Data Privacy**: GDPR compliance considerations
- **Audit Trail**: Complete processing history
- **Data Retention**: Configurable retention policies
- **Access Controls**: Role-based permissions

## ğŸ› ï¸ Troubleshooting

### Common Issues

#### OCR Problems
```bash
# Check Tesseract installation
tesseract --version

# Test OCR functionality
tesseract test_image.png output.txt
```

#### Database Issues
```bash
# Check database permissions
ls -la data/

# Verify database integrity
sqlite3 data/main_documents.db ".schema"
```

#### API Issues
```bash
# Test OpenAI API connection
python -c "import openai; print('API Key configured')"

# Check network connectivity
curl -I https://api.openai.com
```

### Debug Mode
```bash
# Enable debug logging
export LANGGRAPH_VERBOSE=True
export LOG_LEVEL=DEBUG

# Run with verbose output
python main.py document.pdf --debug
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/new-feature`)
3. Make your changes
4. Add tests for your changes
5. Run the test suite (`python -m pytest`)
6. Commit your changes (`git commit -am 'Add new feature'`)
7. Push to the branch (`git push origin feature/new-feature`)
8. Create a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **LangGraph**: For the workflow orchestration framework
- **LangChain**: For LLM integration and agent framework
- **Tesseract**: For OCR capabilities
- **OpenCV**: For image preprocessing
- **OpenAI**: For AI-powered enhancements

## ğŸ“ Support

For issues and questions:
- ğŸ“§ Create an issue on GitHub
- ğŸ“š Check the [documentation](docs/)
- ğŸ”§ Review the [configuration examples](backend/.env.example)
- ğŸ’¬ Join our community discussions

---

**Built with â¤ï¸ for efficient document processing**
